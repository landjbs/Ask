'''
Answer model uses GRU over GPT2 embeddings followed by convo and dense layers
to employ span selection.
'''

'''
Longshot is a model that generates task-specific CLS vectors by running
RNN over GPT-encoded text annotated by span binary dim and attempts to generate
latent dense vector that can be decoded by another LSTM to produce the text
of the question to which the spanned text pertains
'''

import torch
import numpy as np
from torch import nn
from tqdm import tqdm, trange
from termcolor import colored
import matplotlib.pyplot as plt
import torch.nn.functional as F
from torch.cuda import is_available as gpu_available

import utils as u

ZERO_BOOSTER = 0.000000001

class QuestionEncoder(nn.Module):
    '''
    The QuestionEncoder reads over GPT2 vecs of question tokens to encode
    cell state representing pertinent question. Also used in LongShot
    for CLS vector of question approx.
    '''
    super(QuestionEncoder, self).__init__()
    self.hiddenDim = hiddenDim
    self.layerNum = layerNum
    self.rnn = nn.GRU(input_size=hiddenDim,
                      hidden_size=hiddenDim,
                      num_layers=layerNum,
                      batch_first=True)
    def initialize_hidden(self, device):
        """ Init hidden state passed to first RNN cell in time series """
        initTensor =  torch.zeros(1, 1, self.hiddenDim, device=device)
        return initTensor
        # return nn.init.xavier_uniform_(initTensor).float()

    def forward(self, curVec, hidden):
        """
        Forward pass over GPT2 embedding vectors updates rnn cell state for
        later decoding
        """
        curVec = torch.tensor(curVec).float()
        curVec = curVec.view(1, 1, -1)
        outSeq, hidden = self.rnn(curVec, hidden)
        return outSeq, hidden

class AnswerRNN(nn.Module):
    def __init__(self, hiddenDim, layerNum):
        '''
        The Answer RNN reads over GPT2 encdoded context questions after being
        initialized by cell state of QuesitonEncoder
        '''
        super(AnswerRNN, self).__init__()
        self.hiddenDim = hiddenDim
        self.layerNum = layerNum
        self.rnn = nn.GRU(input_size=hiddenDim,
                          hidden_size=hiddenDim,
                          num_layers=layerNum,
                          batch_first=True)

    def forward(self, curVec, hidden):
        """
        Forward pass over GPT2 embedding vectors updates rnn cell state for
        later decoding
        """
        curVec = torch.tensor(curVec).float()
        curVec = curVec.view(1, 1, -1)
        outSeq, hidden = self.rnn(curVec, hidden)
        return outSeq, hidden


class Decoder(nn.Module):
    def __init__(self, hiddenDim, outDim, layerNum):
        '''
        The Decoder Model uses the cell state of the Encoder Model run across
        the word embeddings of the spannotated context to produce step-by-step
        categorical predictions of the character-level encoding of the question
        relating to the current context and span.
        Args:
            hiddenDim:      The size of the hidden vector passed from Encoder
            outDim:         The dimensionality of the character-level space
            layerNum:       The number of layers used by the RNN
        '''
        # INHERIT
        super(Decoder, self).__init__()
        # PARAMS
        self.hiddenDim = hiddenDim
        self.layerNum = layerNum
        self.outDim = outDim
        # LAYERS
        self.embedding = nn.Embedding(outDim, hiddenDim)
        self.rnn = nn.GRU(input_size=hiddenDim,
                          hidden_size=hiddenDim,
                          num_layers=layerNum,
                          batch_first=True)
        self.dense = nn.Linear(in_features=hiddenDim,
                               out_features=outDim)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, prevId, hidden):
        """
        Forward pass uses hidden layer generated by encoder and returns tuple
        of softmax categorical vectors across time series and hidden state
        """
        embedOut = self.embedding(torch.Tensor([prevId]).long()).view(1, 1, -1)
        # embedOut = torch.zeros((37), dtype=torch.long)
        # embedOut[prevId] = 1
        # embedOut = embedOut.view(1, 1, -1)
        embedOut = F.relu(embedOut)
        # print(f'{"EMBEDDING "*10}\n{embedOut}\n{"EMBEDDING "*10}')
        rnnOut, hidden = self.rnn(embedOut, hidden)
        # print(f'{"RNN "*30}\n{rnnOut}\n{"RNN "*30}')
        denseOut = self.dense(rnnOut[0])
        # print(f'{"DENSE "*30}\n{denseOut}\n{"DENSE "*30}')
        outSeq = self.softmax(denseOut)
        return outSeq, hidden


class LongShot(object):
    def __init__(self, searchTable, decoderMax=500):
        '''
        The LongShot Model aggregates the Encoder and Decoder to transform
        spannoated context into text prediction of pertinant question.
        Args:
            searchTable:        SearchTable object initialized with training
                                database
            decoderMax:         Max length of decoder char-level generations
        '''
        # assert
        assert searchTable.initialized, 'SearchTable must be initialized.'
        u.assert_type(decoderMax, 'decoderMax', int)
        # initialize models
        hiddenDim = searchTable.wordEmbeddingSize + 1
        outDim = searchTable.charEmbeddingSize
        self.encoder = Encoder(hiddenDim, layerNum=1)
        self.decoder = Decoder(hiddenDim, outDim, layerNum=1)
        self.encoderOptim = torch.optim.Adam(self.encoder.parameters(), lr=0.0005)
        self.decoderOptim = torch.optim.Adam(self.decoder.parameters(), lr=0.0005)
        # define vars
        self.decoderMax = decoderMax
        self.startId = searchTable.char_encode([searchTable.startToken])
        self.endId = searchTable.char_encode([searchTable.endToken])
        self.searchTable = searchTable
        self.device = torch.device("cuda" if gpu_available() else "cpu")

    def categorical_loss(self, predVec, targetId):
        """ Custom loss function to play with """
        predCorrect = predVec[targetId] + ZERO_BOOSTER
        predLog = torch.log(predCorrect)
        loss = -(predLog)
        return loss

    def inclusion_loss(self, outVec, trueList, decoderOut):
        numC = 0
        r = decoderOut[0] * 0
        print(r)
        print(outVec)
        for trueElt in set(trueList):
            trueElt = trueElt[0].item()
            print(trueElt)
            if trueElt in outVec:
                numC += 1
                print(self.searchTable.word_decode(trueElt))
        rawLoss = r + torch.tensor((numC / len(outVec)) + ZERO_BOOSTER)
        print(f'RAW: {rawLoss}')
        loss = -(torch.log(rawLoss))
        print(f'Log: {loss}')
        return loss

    def general_loss(self, predVec, questionTargets, prevIds):
        curLoss = 0
        questionTargets = set(questionTargets)
        for prev in prevIds:
            if prev in questionTargets:
                questionTargets.remove(prev)
        for target in questionTargets:
            predStrength = predVec[target] + ZERO_BOOSTER
            curLoss -= torch.log(predStrength)
        return curLoss

    def eval_accuracy(self, prediction, target):
        """ Evaluates accuracy of prediciton """
        return 1 if (prediction == target) else 0

    def train_step(self, contextVecs, questionTargets):
        '''
        Trains model on context/question pair. Runs single pass over spannotated
        GPT static embeddings of context paragraph. Passes cell state of encoder
        rnn to decoder rnn for character-level question approximation.
        Evaluated against real question ids and backpropped.
        Args:
            contextVecs:        Vectors of GPT-embedded context (no annotations)
            questionTargets:    Ordered iterable of char ids in question
        Returns:
            Loss across all decoder predictions on current question
        '''
        # clear optimizer gradients
        self.encoderOptim.zero_grad()
        self.decoderOptim.zero_grad()
        # accumulator for loss and accuracy across data
        loss, numCorrect = 0, 0
        # generate initial hidden state for encoder rnn
        encoderHidden = self.encoder.initialize_hidden(self.device)
        # run encoder across samples
        for encoderStep, wordEmbedding in enumerate(contextVecs):
            (encoderOut,
             encoderHidden) = self.encoder(wordEmbedding, encoderHidden)
            _ = encoderOut[0, 0]
        targetLen = len(questionTargets)
        # get id of start char to kick-off decoder
        # decoderInput = self.startId
        decoderInput = self.searchTable.word_encode(['\t'])
        # initial decoder hidden state is final encoder hidden state
        decoderHidden = encoderHidden
        print('Target: ', self.searchTable.word_decode(questionTargets))
        genList = []
        # run decoder across encoderOuts, initializing with encoderHidden
        for decoderStep in range(targetLen):
            (decoderOut,
             decoderHidden) = self.decoder(decoderInput, decoderHidden)
            decoderOut = decoderOut[0]
            # fetch most recent decoder pred for next step input
            _, topi = decoderOut.topk(1)
            decoderInput = topi.squeeze().detach()
            teacherInput = torch.Tensor([questionTargets[decoderStep]]).long()
            # update loss and check if decoder has ouput END char
            loss += self.categorical_loss(decoderOut, teacherInput)
            numCorrect += self.eval_accuracy(decoderInput, teacherInput)
            genList.append(decoderInput.item())
            if (decoderInput.item() == (self.searchTable.gptTokenizer.all_special_ids)[0]):
                print('DONE')
                break
            decoderInput = teacherInput
        print(''.join([self.searchTable.word_decode([x]) for x in genList]))
        # backprop loss, increment optimizers, and return loss across preds
        loss.backward()
        self.encoderOptim.step()
        self.decoderOptim.step()
        print(f'\nLoss: {loss} Acc: {numCorrect}\n{"-"*80}')
        return (loss.item() / decoderStep), (numCorrect / decoderStep)

    def manual_test(self):
        print(f'{"-"*80}')
        while True:
            t = input('text: ')
            if t == 'break':
                break
            span = (0,0)
            tTokens = self.searchTable.word_tokenize(t)
            tIds = self.searchTable.word_encode(tTokens)
            tVecs = np.array(self.searchTable.word_embed(tIds))
            spanDim = np.zeros(shape=(tVecs.shape[0], 1))
            tVecs = np.concatenate((tVecs, spanDim), axis=1)
            q = input('question: ')
            qTokens = self.searchTable.word_tokenize(q)
            qIds = self.searchTable.word_encode(qTokens)
            self.train_step(tVecs, qIds)

    def train(self, epochs, plot=False):
        '''
        Trains both encoder and decoder on SearchTable for iterations.
        Uses only questions with answers. Handles all GPT and character
        embeddings. SearchTable is immediately ready for training after
        initialization.
        Args:
            epochs:         Number of passes to make over ALL data in table
            plot (opt):     Whether to generate plots of training progress
        Returns:
            Tuple of form (trained_encoder, trained_decoder)
        '''
        # initialize vecs to store loss over time
        lossVec, accVec, testLossVec, testAccVec = [], [], [], []
        print(colored(f'Training for {epochs}', 'red'))
        # train over data for epochs
        for epoch in trange(epochs):
            for doc in self.searchTable.iter_docs():
                wordIds = doc.text
                # embed doc ids with GPT2 and add empty annotation dim
                contextVecs = np.array(self.searchTable.word_embed(wordIds))
                spanDim = np.zeros(shape=(contextVecs.shape[0], 1))
                contextVecs = np.concatenate((contextVecs, spanDim), axis=1)
                for question, span in doc.iter_questions():
                    if not span:
                        break
                    if i > 0:
                        break
                    for _ in range(100):
                        print(f'Context: {self.searchTable.word_decode(wordIds)}')
                        # edit span dimension for current question
                        contextVecs[span[0] : span[1]+1, -1] = 1
                        # train for one step on context vecs
                        loss, acc = self.train_step(contextVecs, question)
                        # reset annotation dimension
                        contextVecs[:, -1] = 0
                        lossVec.append(loss)
                        accVec.append(acc)
                        if (round % 50) == 0:
                            self.manual_test()
        return lossVec, accVec
