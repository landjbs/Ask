'''
Longshot is a model that generates task-specific CLS vectors by running
RNN over GPT-encoded text annotated by span binary dim and attempts to generate
latent dense vector that can be decoded by another LSTM to produce the text
of the question to which the spanned text pertains
'''

import torch
import numpy as np
from torch import nn
from tqdm import tqdm, trange
import matplotlib.pyplot as plt

from stucts import SearchTable

# first term is length of word embeddings; second is span dim
EMBEDDING_SIZE = 784 + 1
# number of dims for categorical outputs (letters, numbers, stopchars, etc)
OUT_SIZE = 26 + 1
# stop token tells the decoder to stop running
STOP_TOKEN = '*'
# maximum number of characters the decoder is allowed to generate per run
DECODER_MAX = 500

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class Encoder(nn.Module):
    def __init__(self, hiddenDim, layerNum, lr):
        super(Encoder, self).__init__()
        self.hiddenDim = hiddenDim
        self.layerNum = layerNum
        self.optimizer = torch.optim.Adam(self.encoder.parameters(), lr=lr)
        # TODO: Implement GPT embeddings
        # self.embedding = nn.Embedding(batcherObj.vocabSize, hiddenDim)
        self.rnn = nn.GRU(input_size=hiddenDim,
                          hidden_size=EMBEDDING_SIZE,
                          num_layers=layerNum,
                          batch_first=True)

    def initialize_hidden(self, device):
        """ Init hidden state passed to first RNN cell in time series """
        # initTensor =  torch.zeros(1, 1, self.hiddenDim, device=device)
        return nn.init.xavier_uniform_(initTensor).float()
        return initTensor

    def forward(self, curVec, hidden):
        """
        Forward pass over GPT2 embedding vectors updates rnn cell state for
        later decoding
        """
        # TODO: check shaping of curVec
        curVec = curVec.view(1, 1, -1)
        outSeq, hidden = self.rnn(curVec, hidden)
        return outSeq, hidden


class Decoder(nn.Module):
    def __init__(self, hiddenDim, layerNum, lr):
        # INHERIT
        super(Decoder, self).__init__()
        # PARAMS
        self.hiddenDim = hiddenDim
        self.layerNum = layerNum
        self.optimizer = torch.optim.Adam(self.encoder.parameters(), lr=lr)
        # LAYERS
        self.rnn = nn.GRU(input_size=hiddenDim,
                          hidden_size=EMBEDDING_SIZE,
                          num_layers=layerNum,
                          batch_first=True)
        self.dense = nn.Linear(in_features=hiddenDim,
                               out_features=batcherObj.vocabSize)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, prevId, hidden):
        """
        Forward pass uses hidden layer generated by encoder and returns tuple
        of softmax categorical vectors across time series and hidden state
        """
        embedOut = self.embedding(prevId).view(1, 1, -1)
        rnnOut, hidden = self.rnn(embedOut, hidden)
        denseOut = self.dense(rnnOut[0])
        outSeq = self.softmax(denseOut)
        return outSeq, hidden


class LongShot(object):
    ''' The LongShot model which aggregates the Encoder and Decoder '''
    def __init__(self):
        self.encoder = Encoder(hiddenDim, layerNum, lr)
        self.decoder = Decoder(hiddenDim, layerNum, lr)

    def categorical_loss(self, predVec, targetId):
        """ Custom loss function to play with """
        predCorrect = predVec[0, targetId]
        predLog = torch.log(predCorrect)
        return -(predLog)

    def eval_accuracy(self, predVec, targetId, teacherForce=True):
        """ Evaluates accuracy of prediciton """
        return 1 if (predVec.max(1)[1] == targetId.max()) else 0

    def train_step(self, contextVecs, span, questionText):
        '''
        Trains model on context/question pair. Runs single pass over vector
        embeddings of context paragraph after adding question-specific
        spannotations (haha). Passes cell state of encoder rnn to decoder rnn
        for character-level question approximation. Evaluated against question
        and backpropped.
        Args:
            contextVecs:        Vectors of GPT-embedded context (no annotations)
            span:               Tuple of span start and end loc for adding
                                    spannotations to contextVecs
            questionText:       String of question text with which to eval model
            teacherForce:       Bool indicating whether to use teacher forcing
                                    in decoder text-generation
        Returns:
            Loss across all decoder predictions on current question
        '''
        # clear optimizer gradients
        self.encoder.optimizer.zero_grad()
        self.decoder.optimizer.zero_grad()
        # accumulator for loss and accuracy across data
        loss, numCorrect = 0, 0
        # generate initial hidden state for encoder rnn
        encoderHidden = self.encoder.initialize_hidden(self.device)
        # run encoder across samples
        for encoderStep, wordEmbedding in enumerate(contextVecs):
            (encoderOut,
             encoderHidden) = self.encoder(wordEmbedding, encoderHidden)
             # TODO: decide what to do with encoder outs
            _ = encoderOut[0, 0]
        # TODO: Get targets by running splitting function from object methods
        targets = [c for c in questionText]
        targetLen = len(targets)
        # TODO: Get embedding of start char to kick-off decoder
        decoderInput = None
        # initial decoder hidden state is final encoder hidden state
        # REVIEW: does encoder hidden need to be saved
        decoderHidden = encoderHidden
        # run decoder across encoderOuts, initializing with encoderHidden
        for decoderStep in range(DECODER_MAX):
            (decoderOut,
             decoderHidden) = self.decoder(decoderInput, decoderHidden)
            # fetch most recent decoder pred for next step input
            _, topi = decoderOut.topk(1)
            decoderInput = topi.squeeze().detach()
            # find what the decoder is supposed to ouput
            if (decoderStep <= targetLen):
                curTarget = targets[decoderStep]
            else:
                curTarget = None
            # update loss and check if decoder has ouput END char
            loss += self.categorical_loss(decoderOut, targets[decoderStep])
            numCorrect += self.eval_accuracy(decoderOut, targets[decoderStep])
            if decoderInput.item() == 'STOP_CHAR_NUM_TO_DO':
                break

        def train(self, searchTable, epochs, plot=False):
            '''
            Trains both encoder and decoder on SearchTable for iterations.
            Uses only questions with answers. Handles all GPT and character
            embeddings. SearchTable is immediately ready for training after
            initialization.
            Args:
                searchTable:    Initialized SearchTable object to train on
                epochs:         Number of passes to make over ALL data in table
                plot (opt):     Whether to generate plots of training progress
            Returns:
                Tuple of form (trained_encoder, trained_decoder)
            '''
            # initialize vecs to store loss over time
            lossVec, accVec, testLossVec, testAccVec = [], [], [], []

            # train over data for epochs
            for epoch in trange(epochs):
                for doc in searchTable.iter_docs():
                    docEmbedding =
