'''
Longshot is a model that generates task-specific CLS vectors by running
RNN over GPT-encoded text annotated by span binary dim and attempts to generate
latent dense vector that can be decoded by another LSTM to produce the text
of the question to which the spanned text pertains
'''

import torch
import numpy as np
from torch import nn
from tqdm import tqdm, trange
from termcolor import colored
import matplotlib.pyplot as plt
from torch.cuda import is_available as gpu_available
from transformers import GPT2LMHeadModel, GPT2Tokenizer

import utils as u

class Encoder(nn.Module):
    def __init__(self, hiddenDim, layerNum):
        '''
        The Encoder Model runs an RNN over GPT2 fixed embeddings of byte-pair
        encoded spannotated context to produce a cell state used by the Decoder
        to predict the pertinant question.
        NOTE: Might benefit by replacing RNN with attention mechanism.
        Args:
            hiddenDim:      The dimensionality of the cell state
            layerNum:       The number of layers employed by the RNN
        '''
        super(Encoder, self).__init__()
        self.hiddenDim = hiddenDim
        self.layerNum = layerNum
        self.rnn = nn.GRU(input_size=hiddenDim,
                          hidden_size=hiddenDim,
                          num_layers=layerNum,
                          batch_first=True)

    def initialize_hidden(self, device):
        """ Init hidden state passed to first RNN cell in time series """
        initTensor =  torch.zeros(1, 1, self.hiddenDim, device=device)
        return nn.init.xavier_uniform_(initTensor).float()

    def forward(self, curVec, hidden):
        """
        Forward pass over GPT2 embedding vectors updates rnn cell state for
        later decoding
        """
        curVec = curVec.view(1, 1, -1)
        outSeq, hidden = self.rnn(curVec, hidden)
        return outSeq, hidden


class Decoder(nn.Module):
    def __init__(self, hiddenDim, outDim, layerNum):
        '''
        The Decoder Model uses the cell state of the Encoder Model run across
        the word embeddings of the spannotated context to produce step-by-step
        categorical predictions of the character-level encoding of the question
        relating to the current context and span.
        Args:
            hiddenDim:      The size of the hidden vector passed from Encoder
            outDim:         The dimensionality of the character-level space
            layerNum:       The number of layers used by the RNN
        '''
        # INHERIT
        super(Decoder, self).__init__()
        # PARAMS
        self.hiddenDim = hiddenDim
        self.layerNum = layerNum
        # LAYERS
        self.rnn = nn.GRU(input_size=hiddenDim,
                          hidden_size=hiddenDim,
                          num_layers=layerNum,
                          batch_first=True)
        self.dense = nn.Linear(in_features=hiddenDim,
                               out_features=outDim)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, prevId, hidden):
        """
        Forward pass uses hidden layer generated by encoder and returns tuple
        of softmax categorical vectors across time series and hidden state
        """
        embedOut = self.embedding(prevId).view(1, 1, -1)
        rnnOut, hidden = self.rnn(embedOut, hidden)
        denseOut = self.dense(rnnOut[0])
        outSeq = self.softmax(denseOut)
        return outSeq, hidden


class LongShot(object):
    def __init__(self, searchTable, decoderMax=500):
        '''
        The LongShot Model aggregates the Encoder and Decoder to transform
        spannoated context into text prediction of pertinant question.
        Args:
            searchTable:        SearchTable object initialized with training
                                database
            decoderMax:         Max length of decoder char-level generations
        '''
        # assert
        assert searchTable.initialized, 'SearchTable must be initialized.'
        u.assert_type(decoderMax, 'decoderMax', int)
        # initialize models
        hiddenDim = searchTable.wordEmbeddingSize + 1
        outDim = searchTable.charEmbeddingSize
        self.encoder = Encoder(hiddenDim, layerNum=1)
        self.decoder = Decoder(hiddenDim, outDim, layerNum=1)
        self.encoderOptim = torch.optim.Adam(self.encoder.parameters(), lr=1)
        self.decoderOptim = torch.optim.Adam(self.decoder.parameters(), lr=1)
        # define vars
        self.decoderMax = decoderMax
        startId = searchTable.char_encode([searchTable.startToken])
        endId = searchTable.char_encode([searchTable.endToken])
        self.startVec = np.zeros(outDim)
        self.startVec[startId] = 1
        self.device = torch.device("cuda" if gpu_available() else "cpu")

    def categorical_loss(self, predVec, targetId):
        """ Custom loss function to play with """
        predCorrect = predVec[0, targetId]
        predLog = torch.log(predCorrect)
        return -(predLog)

    def eval_accuracy(self, predVec, targetId, teacherForce=True):
        """ Evaluates accuracy of prediciton """
        return 1 if (predVec.max(1)[1] == targetId.max()) else 0

    def train_step(self, contextVecs, questionTargets):
        '''
        Trains model on context/question pair. Runs single pass over spannotated
        GPT static embeddings of context paragraph. Passes cell state of encoder
        rnn to decoder rnn for character-level question approximation.
        Evaluated against real question ids and backpropped.
        Args:
            contextVecs:        Vectors of GPT-embedded context (no annotations)
            questionTargets:    Ordered iterable of char ids in question
        Returns:
            Loss across all decoder predictions on current question
        '''
        # clear optimizer gradients
        self.encoderOptim.zero_grad()
        self.decoderOptim.zero_grad()
        # accumulator for loss and accuracy across data
        loss, numCorrect = 0, 0
        # generate initial hidden state for encoder rnn
        encoderHidden = self.encoder.initialize_hidden(self.device)
        # run encoder across samples
        for encoderStep, wordEmbedding in enumerate(contextVecs):
            (encoderOut,
             encoderHidden) = self.encoder(wordEmbedding, encoderHidden)
            _ = encoderOut[0, 0]
        targetLen = len(questionTargets)
        # get embedding of start char to kick-off decoder
        decoderInput = self.searchTable.char_encode()
        # initial decoder hidden state is final encoder hidden state
        decoderHidden = encoderHidden
        # run decoder across encoderOuts, initializing with encoderHidden
        for decoderStep in range(DECODER_MAX):
            (decoderOut,
             decoderHidden) = self.decoder(decoderInput, decoderHidden)
            # fetch most recent decoder pred for next step input
            _, topi = decoderOut.topk(1)
            decoderInput = topi.squeeze().detach()
            # find what the decoder is supposed to ouput
            if (decoderStep <= targetLen):
                curTarget = targets[decoderStep]
            else:
                curTarget = None
            # update loss and check if decoder has ouput END char
            loss += self.categorical_loss(decoderOut, targets[decoderStep])
            numCorrect += self.eval_accuracy(decoderOut, targets[decoderStep])
            if decoderInput.item() == 'STOP_CHAR_NUM_TO_DO':
                break
        # backprop loss, increment optimizers, and return loss across preds
        loss.backward()
        encoderOptim.step()
        decoderOptim.step()
        return (loss.item() / decoderStep), (numCorrect / decoderStep)

    def train(self, epochs, plot=False):
        '''
        Trains both encoder and decoder on SearchTable for iterations.
        Uses only questions with answers. Handles all GPT and character
        embeddings. SearchTable is immediately ready for training after
        initialization.
        Args:
            epochs:         Number of passes to make over ALL data in table
            plot (opt):     Whether to generate plots of training progress
        Returns:
            Tuple of form (trained_encoder, trained_decoder)
        '''

        # initialize vecs to store loss over time
        lossVec, accVec, testLossVec, testAccVec = [], [], [], []


        print(colored(f'Training for {epochs}', 'red'), end='\r')
        # train over data for epochs
        for epoch in trange(epochs):
            for doc in self.searchTable.iter_docs():
                wordIds = doc.text
                # embed doc ids with GPT2 and add empty annotation dim
                contextVecs = np.array(self.searchTable.word_embed(wordIds))
                spanDim = np.zeros(shape=(contextVecs.shape[0], ))
                contextVecs = np.concatenate(contextVecs, spanDim)
                for question, span in doc.iter_questions():
                    if not span:
                        break
                    # edit span dimension for current question
                    contextVecs[span[0] : span[1]+1, -1] = 1
                    # train for one step on context vecs
                    loss, acc = self.train_step(contextVecs, question)
                    # reset annotation dimension
                    contextVecs[:, -1] = 0
